{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "import U-Net.UNET as unet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "# Encoder\n",
    "l1c1 = Conv2D(16, 3, activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "l1d1 = Dropout(0.1)(l1c1)\n",
    "l1c2 = Conv2D(16, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l1d1)\n",
    "l1p = MaxPooling2D((2, 2))(l1c2)\n",
    "\n",
    "l2c1 = Conv2D(32, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l1p)\n",
    "l2d1 = Dropout(0.1)(l2c1)\n",
    "l2c2 = Conv2D(32, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l2d1)\n",
    "l2p = MaxPooling2D((2, 2))(l2c2)\n",
    "\n",
    "l3c1 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l2p)\n",
    "l3d1 = Dropout(0.2)(l3c1)\n",
    "l3c2 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l3d1)\n",
    "l3p = MaxPooling2D((2, 2))(l3c2)\n",
    "\n",
    "l4c1 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l3p)\n",
    "l4d1 = Dropout(0.2)(l4c1)\n",
    "l4c2 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l4d1)\n",
    "l4p = MaxPooling2D((2, 2))(l4c2)\n",
    "\n",
    "# Middle\n",
    "mc1 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l4p)\n",
    "md = Dropout(0.3)(mc1)\n",
    "mc2 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(md)\n",
    "\n",
    "# Decoder\n",
    "l4u = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(mc2)    \n",
    "l4c = concatenate([l4u, l4c2])\n",
    "l4c3 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l4c)\n",
    "l4d2 = Dropout(0.2)(l4c3)\n",
    "l4c4 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l4d2)\n",
    "\n",
    "l3u = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(l4c4)\n",
    "l3c = concatenate([l3u, l3c2])\n",
    "l3c3 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l3c)\n",
    "l3d2 = Dropout(0.2)(l3c3)\n",
    "l3c4 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l3d2)\n",
    "\n",
    "l2u = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(l3c4)\n",
    "l2c = concatenate([l2u, l2c2])\n",
    "l2c3 = Conv2D(32, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l2c)\n",
    "l2d2 = Dropout(0.1)(l2c3)\n",
    "l2c4 = Conv2D(32, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l2d2)\n",
    "\n",
    "l1u = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(l2c4)\n",
    "l1c = concatenate([l1u, l1c2])\n",
    "l1c3 = Conv2D(16, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l1c)\n",
    "l1d2 = Dropout(0.1)(l1c3)\n",
    "l1c4 = Conv2D(16, 3, activation='relu', kernel_initializer='he_normal', padding='same')(l1d2)\n",
    "\n",
    "# Output\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(l1c4)\n",
    "\n",
    "# Create Model\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tools for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkPointer = tf.keras.callbacks.ModelCheckpoint('U-Net.h5', \n",
    "                                                  verbose=1, \n",
    "                                                  save_best_only=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                     patience=2, \n",
    "                                     verbose=1),\n",
    "\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/stage1_train/'\n",
    "TEST_PATH = 'data/stage1_test/'\n",
    "\n",
    "trainIDs = next(os.walk(TRAIN_PATH))[1]\n",
    "testIDs = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "# Get training images\n",
    "\n",
    "XTrain = np.zeros((len(trainIDs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "YTrain = np.zeros((len(trainIDs), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "\n",
    "print(\"Resizing training images and masks\")\n",
    "\n",
    "for n, id_ in tqdm(enumerate(trainIDs), total=len(trainIDs)):\n",
    "    path = TRAIN_PATH + id_\n",
    "\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:, :, :IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    XTrain[n] = img \n",
    "\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(\n",
    "            resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), \n",
    "            axis=-1\n",
    "        )\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    \n",
    "    YTrain[n] = mask\n",
    "\n",
    "# Get testing images\n",
    "XTest = np.zeros((len(testIDs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "\n",
    "print(\"Resizing test images\")\n",
    "for n, id_ in tqdm(enumerate(testIDs), total=len(testIDs)):\n",
    "    path = TEST_PATH + id_\n",
    "\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:, :, :IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    XTest[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show 1 Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = random.randint(0, len(trainIDs))\n",
    "# imshow(XTrain[i])\n",
    "# plt.show()\n",
    "# imshow(np.squeeze(YTrain[i]))\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(XTrain, YTrain, validation_split=0.1, batch_size=16, epochs=25, callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(XTrain))\n",
    "\n",
    "predsTrain = model.predict(XTrain[:int(XTrain.shape[0]*0.9)], verbose=1)\n",
    "predsVal = model.predict(XTrain[int(XTrain.shape[0]*0.9):], verbose=1)\n",
    "predsTest = model.predict(XTest, verbose=1)\n",
    "\n",
    "predsTrain_t = (predsTrain > 0.5).astype(np.uint8)\n",
    "predsVal_t = (predsVal > 0.5).astype(np.uint8)\n",
    "predsTest_t = (predsTest > 0.5).astype(np.uint8)\n",
    "\n",
    "# Sanity Check (Training Sample)\n",
    "ix = random.randint(0, len(predsTrain_t))\n",
    "imshow(XTrain[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(YTrain[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(predsTrain_t[ix]))\n",
    "plt.show()\n",
    "\n",
    "# Sanity Check (Validation Sample)\n",
    "ix = random.randint(0, len(predsVal_t))\n",
    "imshow(XTrain[int(XTrain.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(YTrain[int(YTrain.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(predsVal_t[ix]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
