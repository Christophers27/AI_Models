{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, BCELoss\n",
    "from torch.optim import SGD\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.get_dummies(dataset.drop([\"Churn\", \"Customer ID\"], axis=1))\n",
    "labels = dataset[\"Churn\"].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
    "\n",
    "featureTrain, featureTest, labelTrain, labelTest = train_test_split(features, labels, test_size=0.2)\n",
    "\n",
    "featureTrain = torch.tensor(featureTrain.to_numpy().astype(float))\n",
    "featureTest = torch.tensor(featureTest.to_numpy().astype(float))\n",
    "labelTrain = torch.tensor(labelTrain.to_numpy().astype(float))\n",
    "labelTest = torch.tensor(labelTest.to_numpy().astype(float))\n",
    "\n",
    "class ChurnDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.x_data = featureTrain\n",
    "        self.y_data = labelTrain\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "trainingSet = DataLoader(ChurnDataset(dataset), batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create model (32, 64, 1)\n",
    "        self.model = Sequential(\n",
    "            Linear(6575, 32),\n",
    "            ReLU(),\n",
    "\n",
    "            Linear(32, 64),\n",
    "            ReLU(),\n",
    "\n",
    "            Linear(64, 1),\n",
    "            Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Set optimizer as SGD\n",
    "        self.optimizer = SGD(self.parameters(), lr=0.0001)\n",
    "\n",
    "        # Set loss function as binary cross entropy\n",
    "        self.loss = BCELoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.49798497557640076\n",
      "Epoch: 2, Loss: 0.4121250510215759\n",
      "Epoch: 3, Loss: 0.3391192853450775\n",
      "Epoch: 4, Loss: 0.8715300559997559\n",
      "Epoch: 5, Loss: 0.6026017069816589\n",
      "Epoch: 6, Loss: 0.32133039832115173\n",
      "Epoch: 7, Loss: 0.7252461314201355\n",
      "Epoch: 8, Loss: 0.2249997854232788\n",
      "Epoch: 9, Loss: 0.6199973225593567\n",
      "Epoch: 10, Loss: 0.6163090467453003\n",
      "Epoch: 11, Loss: 0.7888840436935425\n",
      "Epoch: 12, Loss: 0.42025303840637207\n",
      "Epoch: 13, Loss: 0.8173975348472595\n",
      "Epoch: 14, Loss: 0.33355212211608887\n",
      "Epoch: 15, Loss: 0.7276594638824463\n",
      "Epoch: 16, Loss: 0.4970651865005493\n",
      "Epoch: 17, Loss: 0.27258872985839844\n",
      "Epoch: 18, Loss: 0.5820369720458984\n",
      "Epoch: 19, Loss: 0.3173601031303406\n",
      "Epoch: 20, Loss: 0.5132920742034912\n",
      "Epoch: 21, Loss: 0.6749348640441895\n",
      "Epoch: 22, Loss: 0.43367230892181396\n",
      "Epoch: 23, Loss: 0.371406614780426\n",
      "Epoch: 24, Loss: 0.7812720537185669\n",
      "Epoch: 25, Loss: 0.39083385467529297\n",
      "Epoch: 26, Loss: 0.23620931804180145\n",
      "Epoch: 27, Loss: 0.27856674790382385\n",
      "Epoch: 28, Loss: 0.7421338558197021\n",
      "Epoch: 29, Loss: 1.022282361984253\n",
      "Epoch: 30, Loss: 0.2623533606529236\n",
      "Epoch: 31, Loss: 0.5198931694030762\n",
      "Epoch: 32, Loss: 0.10671332478523254\n",
      "Epoch: 33, Loss: 0.28336381912231445\n",
      "Epoch: 34, Loss: 0.6108523607254028\n",
      "Epoch: 35, Loss: 0.3171183466911316\n",
      "Epoch: 36, Loss: 0.6511679291725159\n",
      "Epoch: 37, Loss: 0.3441905975341797\n",
      "Epoch: 38, Loss: 0.08602490276098251\n",
      "Epoch: 39, Loss: 0.6002589464187622\n",
      "Epoch: 40, Loss: 0.3232315182685852\n",
      "Epoch: 41, Loss: 0.4566913843154907\n",
      "Epoch: 42, Loss: 0.6462059020996094\n",
      "Epoch: 43, Loss: 0.3180599808692932\n",
      "Epoch: 44, Loss: 0.89173424243927\n",
      "Epoch: 45, Loss: 0.2907620966434479\n",
      "Epoch: 46, Loss: 0.2800970673561096\n",
      "Epoch: 47, Loss: 0.5175697207450867\n",
      "Epoch: 48, Loss: 0.25908026099205017\n",
      "Epoch: 49, Loss: 0.879162073135376\n",
      "Epoch: 50, Loss: 0.4276597201824188\n",
      "Epoch: 51, Loss: 0.2184717357158661\n",
      "Epoch: 52, Loss: 0.3905056118965149\n",
      "Epoch: 53, Loss: 0.18912336230278015\n",
      "Epoch: 54, Loss: 0.3985666036605835\n",
      "Epoch: 55, Loss: 0.41836017370224\n",
      "Epoch: 56, Loss: 0.618219792842865\n",
      "Epoch: 57, Loss: 0.3472457826137543\n",
      "Epoch: 58, Loss: 0.28317421674728394\n",
      "Epoch: 59, Loss: 0.3830280900001526\n",
      "Epoch: 60, Loss: 0.2832275629043579\n",
      "Epoch: 61, Loss: 0.2503807246685028\n",
      "Epoch: 62, Loss: 0.4103921055793762\n",
      "Epoch: 63, Loss: 0.7397779226303101\n",
      "Epoch: 64, Loss: 0.7922298908233643\n",
      "Epoch: 65, Loss: 0.6044740080833435\n",
      "Epoch: 66, Loss: 0.4106864631175995\n",
      "Epoch: 67, Loss: 0.9728584289550781\n",
      "Epoch: 68, Loss: 0.6249545812606812\n",
      "Epoch: 69, Loss: 0.4326704144477844\n",
      "Epoch: 70, Loss: 0.41716060042381287\n",
      "Epoch: 71, Loss: 1.316425085067749\n",
      "Epoch: 72, Loss: 0.17821282148361206\n",
      "Epoch: 73, Loss: 0.931458592414856\n",
      "Epoch: 74, Loss: 0.22553662955760956\n",
      "Epoch: 75, Loss: 0.7955899238586426\n",
      "Epoch: 76, Loss: 0.8353108763694763\n",
      "Epoch: 77, Loss: 0.5954707860946655\n",
      "Epoch: 78, Loss: 0.8213507533073425\n",
      "Epoch: 79, Loss: 1.673413634300232\n",
      "Epoch: 80, Loss: 0.905648946762085\n",
      "Epoch: 81, Loss: 0.3110524117946625\n",
      "Epoch: 82, Loss: 0.8479411005973816\n",
      "Epoch: 83, Loss: 0.8952698707580566\n",
      "Epoch: 84, Loss: 0.6114469170570374\n",
      "Epoch: 85, Loss: 0.5379822254180908\n",
      "Epoch: 86, Loss: 0.5062944293022156\n",
      "Epoch: 87, Loss: 0.10106310248374939\n",
      "Epoch: 88, Loss: 0.42781370878219604\n",
      "Epoch: 89, Loss: 0.20369450747966766\n",
      "Epoch: 90, Loss: 0.8250421285629272\n",
      "Epoch: 91, Loss: 0.5332685112953186\n",
      "Epoch: 92, Loss: 0.5793513059616089\n",
      "Epoch: 93, Loss: 0.2751012146472931\n",
      "Epoch: 94, Loss: 0.35000261664390564\n",
      "Epoch: 95, Loss: 0.9704315066337585\n",
      "Epoch: 96, Loss: 0.10335253179073334\n",
      "Epoch: 97, Loss: 0.32475441694259644\n",
      "Epoch: 98, Loss: 1.1017650365829468\n",
      "Epoch: 99, Loss: 0.8932522535324097\n",
      "Epoch: 100, Loss: 0.3899068236351013\n",
      "Epoch: 101, Loss: 0.3372034728527069\n",
      "Epoch: 102, Loss: 0.4503682851791382\n",
      "Epoch: 103, Loss: 0.37553781270980835\n",
      "Epoch: 104, Loss: 0.6019091606140137\n",
      "Epoch: 105, Loss: 0.18906256556510925\n",
      "Epoch: 106, Loss: 0.44427651166915894\n",
      "Epoch: 107, Loss: 0.4455762803554535\n",
      "Epoch: 108, Loss: 0.11252500861883163\n",
      "Epoch: 109, Loss: 0.6113453507423401\n",
      "Epoch: 110, Loss: 0.3215112090110779\n",
      "Epoch: 111, Loss: 0.5061403512954712\n",
      "Epoch: 112, Loss: 0.20577749609947205\n",
      "Epoch: 113, Loss: 0.3618505001068115\n",
      "Epoch: 114, Loss: 0.3907640874385834\n",
      "Epoch: 115, Loss: 0.3688846826553345\n",
      "Epoch: 116, Loss: 0.21992844343185425\n",
      "Epoch: 117, Loss: 0.3183287978172302\n",
      "Epoch: 118, Loss: 0.47181808948516846\n",
      "Epoch: 119, Loss: 0.3831341862678528\n",
      "Epoch: 120, Loss: 1.4805988073349\n",
      "Epoch: 121, Loss: 0.35729604959487915\n",
      "Epoch: 122, Loss: 0.3375188112258911\n",
      "Epoch: 123, Loss: 0.6314688920974731\n",
      "Epoch: 124, Loss: 0.8186177015304565\n",
      "Epoch: 125, Loss: 0.4481450915336609\n",
      "Epoch: 126, Loss: 0.4362420439720154\n",
      "Epoch: 127, Loss: 0.4417869448661804\n",
      "Epoch: 128, Loss: 0.5124690532684326\n",
      "Epoch: 129, Loss: 0.3559539318084717\n",
      "Epoch: 130, Loss: 0.5351768136024475\n",
      "Epoch: 131, Loss: 0.17908746004104614\n",
      "Epoch: 132, Loss: 0.1803748458623886\n",
      "Epoch: 133, Loss: 0.7558469772338867\n",
      "Epoch: 134, Loss: 0.7182682752609253\n",
      "Epoch: 135, Loss: 0.2515438497066498\n",
      "Epoch: 136, Loss: 0.5844054222106934\n",
      "Epoch: 137, Loss: 0.15152999758720398\n",
      "Epoch: 138, Loss: 0.44009947776794434\n",
      "Epoch: 139, Loss: 0.16678957641124725\n",
      "Epoch: 140, Loss: 0.3248758316040039\n",
      "Epoch: 141, Loss: 0.6277559995651245\n",
      "Epoch: 142, Loss: 0.4093113839626312\n",
      "Epoch: 143, Loss: 0.3279981315135956\n",
      "Epoch: 144, Loss: 0.2276766151189804\n",
      "Epoch: 145, Loss: 0.6791297197341919\n",
      "Epoch: 146, Loss: 0.41642290353775024\n",
      "Epoch: 147, Loss: 0.31903761625289917\n",
      "Epoch: 148, Loss: 0.31365907192230225\n",
      "Epoch: 149, Loss: 0.1561058610677719\n",
      "Epoch: 150, Loss: 0.9192430973052979\n",
      "Epoch: 151, Loss: 1.4797546863555908\n",
      "Epoch: 152, Loss: 0.5472549796104431\n",
      "Epoch: 153, Loss: 0.3506051003932953\n",
      "Epoch: 154, Loss: 0.357602059841156\n",
      "Epoch: 155, Loss: 0.16965655982494354\n",
      "Epoch: 156, Loss: 0.3722888231277466\n",
      "Epoch: 157, Loss: 0.3142964839935303\n",
      "Epoch: 158, Loss: 0.31097620725631714\n",
      "Epoch: 159, Loss: 0.6692317724227905\n",
      "Epoch: 160, Loss: 0.4933892488479614\n",
      "Epoch: 161, Loss: 0.2809220552444458\n",
      "Epoch: 162, Loss: 0.5414605140686035\n",
      "Epoch: 163, Loss: 1.0876225233078003\n",
      "Epoch: 164, Loss: 0.31361570954322815\n",
      "Epoch: 165, Loss: 0.4302792251110077\n",
      "Epoch: 166, Loss: 0.09004734456539154\n",
      "Epoch: 167, Loss: 0.42588934302330017\n",
      "Epoch: 168, Loss: 1.0224579572677612\n",
      "Epoch: 169, Loss: 0.5628920793533325\n",
      "Epoch: 170, Loss: 0.5089641809463501\n",
      "Epoch: 171, Loss: 0.1855768859386444\n",
      "Epoch: 172, Loss: 0.3914715051651001\n",
      "Epoch: 173, Loss: 0.6572706699371338\n",
      "Epoch: 174, Loss: 1.61905837059021\n",
      "Epoch: 175, Loss: 0.38729342818260193\n",
      "Epoch: 176, Loss: 1.604297399520874\n",
      "Epoch: 177, Loss: 0.34708160161972046\n",
      "Epoch: 178, Loss: 0.37085479497909546\n",
      "Epoch: 179, Loss: 0.32027217745780945\n",
      "Epoch: 180, Loss: 0.3589157462120056\n",
      "Epoch: 181, Loss: 0.3246782720088959\n",
      "Epoch: 182, Loss: 0.3776749074459076\n",
      "Epoch: 183, Loss: 0.8175346255302429\n",
      "Epoch: 184, Loss: 0.6449599266052246\n",
      "Epoch: 185, Loss: 0.4184982478618622\n",
      "Epoch: 186, Loss: 0.35271120071411133\n",
      "Epoch: 187, Loss: 0.48112210631370544\n",
      "Epoch: 188, Loss: 0.3713042140007019\n",
      "Epoch: 189, Loss: 0.41614532470703125\n",
      "Epoch: 190, Loss: 0.11270970106124878\n",
      "Epoch: 191, Loss: 0.3654737174510956\n",
      "Epoch: 192, Loss: 0.6373059749603271\n",
      "Epoch: 193, Loss: 0.5268869400024414\n",
      "Epoch: 194, Loss: 0.44140028953552246\n",
      "Epoch: 195, Loss: 0.28659361600875854\n",
      "Epoch: 196, Loss: 0.3483312726020813\n",
      "Epoch: 197, Loss: 0.486264705657959\n",
      "Epoch: 198, Loss: 0.368965744972229\n",
      "Epoch: 199, Loss: 0.7304035425186157\n",
      "Epoch: 200, Loss: 0.3066827058792114\n"
     ]
    }
   ],
   "source": [
    "model = ANN().to(\"cuda\")\n",
    "\n",
    "# Train model\n",
    "for epoch in range(200):\n",
    "    for data, label in trainingSet:\n",
    "        data = data.to(\"cuda\").to(torch.float32)\n",
    "        label = label.to(\"cuda\").to(torch.float32)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data) \n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss(output, label.unsqueeze(1))\n",
    "\n",
    "        # Zero gradients\n",
    "        model.optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        model.optimizer.step() \n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(featureTest.to(\"cuda\").to(torch.float32))\n",
    "y_pred = [1 if x >= 0.5 else 0 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8005677785663591"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labelTest, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
